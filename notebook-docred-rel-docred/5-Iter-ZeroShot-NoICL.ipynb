{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fa0302fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, \"..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7d976a00-8c49-4748-b897-1d57da81a22e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "from auto_chatgpt.autochatgpt.chatgptbot import ChatGPTBot\n",
    "from rel import REL\n",
    "import os\n",
    "import time\n",
    "import json\n",
    "import random\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dd25ff15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kindly update based on your email and password. \n",
    "# For every experiment, change the file_name. This will the file to store the outcome of ChatGPT. \n",
    "# This is to esnure, we do not lose any output if incase there is any unexpected disruption.\n",
    "EMAIL_ADDRESS = \"..\"\n",
    "PASSWORD = \"..\"\n",
    "FILE_NAME = \"5-Iter-ZeroShot-NoICL\"\n",
    "RELATION_LABEL=\"docred\"\n",
    "CONSISTENT_COUNT=5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c735cc23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the ChatGPT Bot\n",
    "new_chat = ChatGPTBot(EMAIL_ADDRESS, PASSWORD, headless=False, wait=60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "826f33d2-dee4-471b-943b-a575dedafa65",
   "metadata": {},
   "source": [
    "## Note:\n",
    "1. Do not remove headless variable. This will ensure us to monitor input and output from ChatGPT. Also it will be easier to indentify if incase there is any issue happened during scrapping.\n",
    "2. Once the above cell complete run, you will see a new browser opens and shows like this:\n",
    "   1. <img src=\"../images/chatgpt-popup.png\" alt=\"Alt text that describes the graphic\" title=\"Title text\" />\n",
    "3. <code style=\"background:yellow;color:black\">Close the popup first before move to run next Jupyter Cell.</code> \n",
    "4. <code style=\"background:yellow;color:black\">Now Select New Chat before running every Experiment.</code>\n",
    "5. Then you can start running below cell\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "50dee8e3-6a7d-42a8-8010-342dbcab4fd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "rel = REL(consistency_count=CONSISTENT_COUNT, relation_label=RELATION_LABEL)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1833af5d",
   "metadata": {},
   "source": [
    "## Start Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "83368dc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the dataset. \n",
    "dt = \"../dataset/docred-dataset.json\"\n",
    "with open(dt) as f:\n",
    "    data = json.load(f)\n",
    "    \n",
    "dataset = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7e8b55bf-e51b-4913-9715-e74783193509",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Milestone Completion: 0\n",
      "You will annotate: 200 News Articles\n"
     ]
    }
   ],
   "source": [
    "# Define the file to save ChatGPT output. \n",
    "# If the file is existing (if you are running after first time), then it will automatically find the articles that are annotated\n",
    "file = f\"rel_annotation_by_chatgpt/{FILE_NAME}.json\"\n",
    "counter_time = 1\n",
    "\n",
    "if os.path.exists(file):\n",
    "    with open(file, \"r\") as f:\n",
    "        existing_data = json.load(f)\n",
    "else:\n",
    "    existing_data = []\n",
    "\n",
    "total = dataset.shape[0]\n",
    "len_existing_data = len(existing_data)\n",
    "print(\"Current Milestone Completion: {}\".format(len_existing_data))\n",
    "print(\"You will annotate: {} News Articles\".format(total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03f2334e",
   "metadata": {},
   "outputs": [],
   "source": [
    "guides = pd.read_csv(f\"../guideline/{RELATION_LABEL}.csv\")\n",
    "\n",
    "for idx, row in dataset.iloc[len_existing_data:total].iterrows():\n",
    "    print(\"Annotating News Article.... {}\".format(idx+1))\n",
    "    article_tr = \" \".join([\" \".join(sentence) for sentence in row[\"sents\"]])\n",
    "    consistency_list = []\n",
    "    for _ in range(CONSISTENT_COUNT):\n",
    "        # Retrieve Entity Pair for each dataset\n",
    "        vertexSet = [item for sublist in row['vertexSet'] for item in sublist]\n",
    "        head = [vertexSet[h]['name'] for h in row['labels']['head']]\n",
    "        tail = [vertexSet[t]['name'] for t in row['labels']['tail']]\n",
    "        entities = [(head[idx],tail[idx]) for idx in range(len(head))]\n",
    "        entity_pairs = [f\"{_+1}. {entities[_]}\" for _ in range(len(entities))]\n",
    "        docred_labels = list(guides[\"Relation Label\"])\n",
    "        output = 'Answer me in JSON format. Follow this format: { \"annotations\": [ { \"entity_pair\": { \"head\": \"Entity\", \"tail\": \"Entity\" }, \"relation\": \"Relation Label\" }, { \"entity_pair\": { \"head\": \"Entity\", \"tail\": \"Entity\" }, \"relation\": \"Relation Label\" } ] }. Only give me the response asked, without any explaination'\n",
    "        prompt_docred = \"You will be provided with List of Entities and News Article as Input. Only annotate the relation based on this labels: {} and guideline provided earlier. {}. Here is the News Article: {} and Entity Pairs: {}\".format(docred_labels,output,article_tr,entity_pairs)\n",
    "    \n",
    "        # Send Prompt in ChatGPT\n",
    "        new_chat.send_prompt(prompt=prompt_docred)\n",
    "        time.sleep(random.randint(10,15))\n",
    "        res_docred = new_chat.get_gpt_response()\n",
    "        time.sleep(random.randint(5,8))\n",
    "        response_docred = res_docred[-1]\n",
    "        time.sleep(random.randint(5,8))\n",
    "        formated_response_doc = rel.response_format(response_docred) # we are not checking if relation is within our relation label scope\n",
    "        time.sleep(random.randint(5,8))\n",
    "        consistency_list.append(formated_response_doc)\n",
    "        \n",
    "    new_response_doc = rel.consistent_checker(consistency_list)\n",
    "    \n",
    "    output_gold = []\n",
    "    relation = [r for r in row['labels']['relation_text']]\n",
    "    relations_gold = [{\"id\": idx, \"head\": head[idx], \"tail\": tail[idx], \"relation\": relation[idx]} for idx in range(len(head))]\n",
    "    for relation in relations_gold:\n",
    "        head = relation[\"head\"]\n",
    "        tail = relation[\"tail\"]\n",
    "        output_gold.append({\"entity_pair\": {\"head\": head, \"tail\": tail}, \"relation\": relation[\"relation\"]})\n",
    "    if not formated_response_doc:  \n",
    "        print(f\"The DocRED is empty for article id {idx+1}\")\n",
    "    existing_data.append({\n",
    "        \"idx\": idx,\n",
    "        \"text\": str(article_tr),\n",
    "        \"chatgpt\": formated_response_doc,\n",
    "        \"gold\": output_gold\n",
    "    })\n",
    "    with open(file, \"w\") as f:\n",
    "        json.dump(existing_data, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3fb1591-de90-45e0-8266-b41c1529d10b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cgpt",
   "language": "python",
   "name": "cgpt"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
