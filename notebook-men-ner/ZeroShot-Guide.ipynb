{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "619ce734-ec6d-4786-9d74-7f77c6419d2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, \"..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0404871c-394c-433c-9c5d-ee1bd985b37b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "from auto_chatgpt.autochatgpt.chatgptbot import ChatGPTBot\n",
    "from ner import NER\n",
    "import os\n",
    "import time\n",
    "import json\n",
    "import random\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3a5572e3-82f2-4310-97f2-4b62745ead32",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "unterminated string literal (detected at line 4) (2994367036.py, line 4)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[3], line 4\u001b[1;36m\u001b[0m\n\u001b[1;33m    EMAIL_ADDRESS = \"..\u001b[0m\n\u001b[1;37m                    ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m unterminated string literal (detected at line 4)\n"
     ]
    }
   ],
   "source": [
    "# Kindly update based on your email and password. \n",
    "# For every experiment, change the file_name. This will the file to store the outcome of ChatGPT. \n",
    "# This is to esnure, we do not lose any output if incase there is any unexpected disruption.\n",
    "EMAIL_ADDRESS = \"..\"\n",
    "PASSWORD = \"..\"\n",
    "FILE_NAME = \"ZeroShot-Guide\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dc9e662-b03c-476d-bf3b-f2dd6b859cf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the ChatGPT Bot\n",
    "new_chat = ChatGPTBot(EMAIL_ADDRESS, PASSWORD, headless=False, wait=60)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "03d6cead-ab96-4e3a-a76e-18052db9ecfd",
   "metadata": {},
   "source": [
    "## Note:\n",
    "1. Do not remove headless variable. This will ensure us to monitor input and output from ChatGPT. Also it will be easier to indentify if incase there is any issue happened during scrapping.\n",
    "2. Once the above cell complete run, you will see a new browser opens and shows like this:\n",
    "   1. <img src=\"../images/chatgpt-popup.png\" alt=\"Alt text that describes the graphic\" title=\"Title text\" />\n",
    "3. <code style=\"background:yellow;color:black\">Close the popup first before move to run next Jupyter Cell.</code> \n",
    "4. <code style=\"background:yellow;color:black\">Now Select New Chat before running every Experiment.</code>\n",
    "5. Then you can start running below cell\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f1b81580-aad9-4b80-afeb-7546a390ad52",
   "metadata": {},
   "outputs": [],
   "source": [
    "ner = NER()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f5e6faf-f7ee-4ffa-9ced-2f0233b727c7",
   "metadata": {},
   "source": [
    "## Provide Annotation Guideline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e04015c-14b6-4a2d-80d2-2ea69484edd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Provide Guideline to ChatGPT\n",
    "guideline = ner.retrieve_guideline()\n",
    "\n",
    "new_chat.send_prompt(prompt=\"Act as a Data Annotator. You will be given an Annotation Guideline, understand the guideline before start annotation. Since the guideline is too long, you will be given as separate chunks.\")\n",
    "# We only take guideline from second page onwards, as the first page is Cover Page.\n",
    "for idx in range(2,len(guideline)):\n",
    "    print(\"Writing chunk number {}/{}\".format(idx-1,len(guideline)))\n",
    "    prompt = \"Here is chunk number {}: {} \\n  If you understand, just response Yes I understand or not you may ask question and no further explanation is required.\".format(idx-1,guideline[idx])\n",
    "    new_chat.send_prompt(prompt=prompt)\n",
    "    time.sleep(random.randint(20,30))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ffa7a1d-2cf0-4fc8-adfd-60d75d2be2eb",
   "metadata": {},
   "source": [
    "## Start Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "16e9e19c-879f-40a5-b8c1-afc0812cf2c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the dataset. \n",
    "dt = \"../dataset/men-dataset.json\"\n",
    "with open(dt) as f:\n",
    "    data = json.load(f)\n",
    "    \n",
    "dataset = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7767e3da-9db3-4a39-a7fe-94a233eb0441",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Milestone Completion: 0\n",
      "You will annotate: 200 News Articles\n"
     ]
    }
   ],
   "source": [
    "# Define the file to save ChatGPT output. \n",
    "# If the file is existing (if you are running after first time), then it will automatically find the articles that are annotated\n",
    "file = f\"ner_annotation_by_chatgpt/{FILE_NAME}.json\"\n",
    "counter_time = 1\n",
    "\n",
    "if os.path.exists(file):\n",
    "    with open(file, \"r\") as f:\n",
    "        existing_data = json.load(f)\n",
    "else:\n",
    "    existing_data = []\n",
    "\n",
    "total = dataset.shape[0]\n",
    "len_existing_data = len(existing_data)\n",
    "print(\"Current Milestone Completion: {}\".format(len_existing_data))\n",
    "print(\"You will annotate: {} News Articles\".format(total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "974da3ae-fe4b-4e59-bdae-c5e7ed846801",
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, row in dataset.iloc[len_existing_data:total].iterrows():\n",
    "    print(\"Annotating News Article.... {}\".format(idx+1))\n",
    "    news_article = row[\"article\"]\n",
    "    # Prompt to extract entities based on Input. The input is New Article\n",
    "    prompt = \"Act as Data Annotator, identify and extract all the entity PERSON, LOCATION, ORGANIZATION, EVENT, WORK_OF_ART, ROLE, TITLE, NORP, FACILITY, PRODUCT, LAW, LANGUAGE from the input news article. Input: {}. Provide the output as JSON.\".format(news_article)\n",
    "    new_chat.send_prompt(prompt=prompt)\n",
    "\n",
    "    # This counter is to set and idle time and prvent from spamming ChatGPT website\n",
    "    if counter_time==25:\n",
    "        time.sleep(random.randint(45,60))\n",
    "        counter_time=1\n",
    "    elif counter_time==15:\n",
    "        time.sleep(random.randint(20,30))\n",
    "        counter_time=counter_time+1\n",
    "    else:\n",
    "        time.sleep(random.randint(8,10))\n",
    "        counter_time=counter_time+1\n",
    "\n",
    "    # Get ChatGPT output for the input given\n",
    "    res = new_chat.get_gpt_response()\n",
    "    time.sleep(random.randint(5,7))\n",
    "    response = res[-1]\n",
    "    time.sleep(random.randint(2,4))\n",
    "    # Format ChatGPT outcome and extract only required output.\n",
    "    formated_response = ner.formatting_chatgpt_response(response)\n",
    "    # Get the offset from each entity.\n",
    "    validated_entity_set = ner.find_offset(row[\"article\"],formated_response) #Only Have Exact Match\n",
    "    existing_data.append({\n",
    "        \"idx\": idx,\n",
    "        \"text\": news_article,\n",
    "        \"chatgpt_ent\": validated_entity_set,\n",
    "        \"gold_ent\": row[\"entities\"]\n",
    "    })\n",
    "    with open(file, \"w\") as f:\n",
    "        json.dump(existing_data, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14fcf023-aced-447a-a4b0-b46e9d866007",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cgpt",
   "language": "python",
   "name": "cgpt"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
